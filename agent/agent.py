from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import SystemMessage, HumanMessage
from typing import Optional, AsyncGenerator, Tuple, Any
from memory_strategy import BaseMemoryStrategy
from trajectory.trajectory_recorder import create_local_recorder
from trajectory.react_trajectory_hook import create_trajectory_hook

def create_agent(
    llm, 
    tools, 
    use_memory=True, 
    memory_strategy: Optional[BaseMemoryStrategy] = None,
    use_trajectory: bool = False,  # æ–°å¢å‚æ•°
    trajectory_recorder: Optional[Any] = None  # æ–°å¢å‚æ•°
):
    """åˆ›å»ºReAct Agent
    
    Args:
        llm: è¯­è¨€æ¨¡å‹
        tools: å·¥å…·åˆ—è¡¨
        use_memory: æ˜¯å¦ä½¿ç”¨è®°å¿†åŠŸèƒ½ï¼Œé»˜è®¤True
        memory_strategy: è®°å¿†ç­–ç•¥å®ä¾‹ï¼Œç”¨äºæ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        use_trajectory: æ˜¯å¦å¯ç”¨è½¨è¿¹è®°å½•
        trajectory_recorder: è‡ªå®šä¹‰çš„è½¨è¿¹è®°å½•å™¨ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤çš„æœ¬åœ°è®°å½•å™¨
    """
    # æ ¹æ®å¯ç”¨å·¥å…·åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤º
    tool_descriptions = []
    for tool in tools:
        tool_descriptions.append(f"- {tool.name}: {tool.description}")
    
    tools_text = "\n".join(tool_descriptions) if tool_descriptions else "æš‚æ— å¯ç”¨å·¥å…·"
    
    system_message = SystemMessage(content=f"""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ï¼š

{tools_text}

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œå¹¶æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·æŒ‰ç…§å·¥å…·çš„å‚æ•°è¦æ±‚æ­£ç¡®è°ƒç”¨ã€‚""")
    
    # æ„å»ºå‚æ•°
    agent_params = {
        "model": llm,
        "tools": tools,
        "prompt": system_message,
    }
    
    # å¤„ç†è®°å¿†ç­–ç•¥
    if not memory_strategy:
        memory_strategy = BaseMemoryStrategy.default_strategy()
        print("âš ï¸ æ²¡æœ‰æä¾›è®°å¿†ç­–ç•¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥, ä¿ç•™æ‰€æœ‰å†å²æ¶ˆæ¯")
    else:
        print(f"âœ… ä½¿ç”¨è®°å¿†ç­–ç•¥: {memory_strategy.__class__.__name__}")
    
    # æ— è®ºæ˜¯é»˜è®¤ç­–ç•¥è¿˜æ˜¯ç”¨æˆ·æä¾›çš„ç­–ç•¥ï¼Œéƒ½éœ€è¦æ·»åŠ  pre_model_hook
    agent_params["pre_model_hook"] = memory_strategy.create_pre_model_hook()
    
    # å¤„ç†è½¨è¿¹è®°å½•
    if use_trajectory:
        trajectory_recorder = trajectory_recorder or create_local_recorder()
        trajectory_hook = create_trajectory_hook(trajectory_recorder)
        agent_params["post_model_hook"] = trajectory_hook

    
    # å¦‚æœå¯ç”¨è®°å¿†ï¼Œæ·»åŠ  checkpointer
    if use_memory:
        agent_params["checkpointer"] = InMemorySaver()
    
    # åªè¿”å› agentï¼Œä¸è¿”å› trajectory_hook
    return create_react_agent(**agent_params)


async def stream_agent(
    agent, 
    query: str, 
    thread_id: str
) -> AsyncGenerator[Tuple[Any, dict], None]:
    """ç»Ÿä¸€çš„Agentè°ƒç”¨æ¥å£ - æµå¼è¾“å‡º
    
    Args:
        agent: Agentå®ä¾‹
        query: ç”¨æˆ·æŸ¥è¯¢
        thread_id: ä¼šè¯ID
    
    Yields:
        Tuple[message_chunk, metadata]: æ¶ˆæ¯å—å’Œå…ƒæ•°æ®
    """
    print(f"\n{'='*50}")
    print(f"ğŸ” å¤„ç†æŸ¥è¯¢: {query}")
    print(f"ğŸ†” ä¼šè¯ID: {thread_id}")
    print(f"{'='*50}\n")
    
    config = {"configurable": {"thread_id": thread_id}}
    inputs = {"messages": [HumanMessage(content=query)]}
    
    async for message_chunk, metadata in agent.astream(
        input=inputs,
        config=config,
        stream_mode="messages"
    ):
        yield message_chunk, metadata