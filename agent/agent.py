from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import SystemMessage, HumanMessage

def create_agent(llm, tools, use_memory=True):
    """åˆ›å»ºReAct Agent
    
    Args:
        llm: è¯­è¨€æ¨¡å‹
        tools: å·¥å…·åˆ—è¡¨
        use_memory: æ˜¯å¦ä½¿ç”¨è®°å¿†åŠŸèƒ½ï¼Œé»˜è®¤True
    """
    # æ ¹æ®å¯ç”¨å·¥å…·åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤º
    tool_descriptions = []
    for tool in tools:
        tool_descriptions.append(f"- {tool.name}: {tool.description}")
    
    tools_text = "\n".join(tool_descriptions) if tool_descriptions else "æš‚æ— å¯ç”¨å·¥å…·"
    
    system_message = SystemMessage(content=f"""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ï¼š

{tools_text}

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œå¹¶æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·æŒ‰ç…§å·¥å…·çš„å‚æ•°è¦æ±‚æ­£ç¡®è°ƒç”¨ã€‚""")
    
    if use_memory:
        checkpointer = InMemorySaver()
        return create_react_agent(
            model=llm,
            tools=tools,
            prompt=system_message,
            checkpointer=checkpointer
        )
    else:
        return create_react_agent(
            model=llm,
            tools=tools,
            prompt=system_message
        )

async def invoke_agent(agent, query: str, thread_id: str) -> dict:
    """éæµå¼è°ƒç”¨Agent"""
    print(f"\n{'='*50}")
    print(f"ğŸ” å¤„ç†æŸ¥è¯¢: {query}")
    print(f"ğŸ†” ä¼šè¯ID: {thread_id}")
    print(f"{'='*50}\n")
    
    # æ„é€ è¾“å…¥
    inputs = {
        "messages": [HumanMessage(content=query)]
    }
    
    # è°ƒç”¨agentå¹¶è·å–å®Œæ•´å“åº”
    response = await agent.ainvoke(
        inputs,
        config={"configurable": {"thread_id": thread_id}}
    )
    
    # ç¡®ä¿è¿”å›å®Œæ•´çš„æ¶ˆæ¯å†å²
    if isinstance(response, dict):
        # å¦‚æœresponseä¸­åŒ…å«messagesï¼Œç›´æ¥è¿”å›
        if "messages" in response:
            print(f"âœ… Agentè¿”å›äº† {len(response['messages'])} æ¡æ¶ˆæ¯")
            return response
        else:
            # å¦‚æœæ²¡æœ‰messagesï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹è·å–
            print("âš ï¸ Agentå“åº”ä¸­æ²¡æœ‰messageså­—æ®µ")
            return {"messages": []}
    else:
        print(f"âš ï¸ Agentè¿”å›äº†éå­—å…¸ç±»å‹: {type(response)}")
        return {"messages": []}

async def stream_agent(agent, user_input: str, thread_id: str = "1"):
    """æµå¼è°ƒç”¨Agent"""
    config = {"configurable": {"thread_id": thread_id}}
    async for message_chunk, metadata in agent.astream(
        input={"messages": [HumanMessage(content=user_input)]},
        config=config,
        stream_mode="messages"
    ):
        yield message_chunk, metadata